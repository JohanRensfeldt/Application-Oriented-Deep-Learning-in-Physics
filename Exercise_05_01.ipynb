{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF2trPuyzm9C"
      },
      "source": [
        "# Exercise 5.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ipcsUFDUzm9C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCJe_ITJzm9G"
      },
      "source": [
        "**Simple Network**\n",
        "\n",
        "We continue with the dataset first encountered in the previous exercise. Please refer to the discussion there for an introduction to the data and the learning objective.\n",
        "\n",
        "Here, we manually implement a simple network architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NopU99AT9G7s",
        "outputId": "d7e8848e-b9c0-4eb4-8f18-5acda9d8c343"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "# The code snippet below is responsible for downloading the dataset\n",
        "# - for example when running via Google Colab.\n",
        "#\n",
        "# You can also directly download the file using the link if you work\n",
        "# with a local setup (in that case, ignore the !wget)\n",
        "\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ONqeI5Uzm9H",
        "outputId": "d31ba8d4-cf0a-4f25-8a93-9091c0dd041a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data: (4898, 12)\n",
            "First example:\n",
            "Features: [6.5000e+00 3.2000e-01 3.4000e-01 5.7000e+00 4.4000e-02 2.7000e+01\n",
            " 9.1000e+01 9.9184e-01 3.2800e+00 6.0000e-01 1.2000e+01]\n",
            "Quality: 7.0\n"
          ]
        }
      ],
      "source": [
        "# Before working with the data, \n",
        "# we download and prepare all features\n",
        "\n",
        "# load all examples from the file\n",
        "data = np.genfromtxt('winequality-white.csv',delimiter=\";\",skip_header=1)\n",
        "\n",
        "print(\"data:\", data.shape)\n",
        "\n",
        "# Prepare for proper training\n",
        "np.random.shuffle(data) # randomly sort examples\n",
        "\n",
        "# take the first 3000 examples for training\n",
        "# (remember array slicing from last week)\n",
        "X_train = data[:3000,:11] # all features except last column\n",
        "y_train = data[:3000,11]  # quality column\n",
        "\n",
        "# and the remaining examples for testing\n",
        "X_test = data[3000:,:11] # all features except last column\n",
        "y_test = data[3000:,11] # quality column\n",
        "\n",
        "print(\"First example:\")\n",
        "print(\"Features:\", X_train[0])\n",
        "print(\"Quality:\", y_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiwnyNHpzm9L"
      },
      "source": [
        "# Problems\n",
        "\n",
        "The goal is to implement the training of a neural network with one input layer, one hidden layer, and one output layer using gradient descent. We first (below) define the matrices and initialise with random values. We need W, b, W' and b'. The shapes will be:\n",
        "  * W: (number of hidden nodes, number of inputs) named `W`\n",
        "  * b: (number of hidden nodes) named `b`\n",
        "  * W': (number of hidden nodes) named `Wp`\n",
        "  * b': (one) named `bp`\n",
        "\n",
        "Your tasks are:     \n",
        "   * Implement a forward pass of the network as `dnn` (see below)\n",
        "   * Implement a function that uses one data point to update the weights using gradient descent. You can follow the `update_weights` skeleton below\n",
        "   * Now you can use the code below (training loop and evaluation) to train the network for multiple data points and even over several epochs. Try to find a set of hyperparameters (number of nodes in the hidden layer, learning rate, number of training epochs) that gives stable results. What is the best result (as measured by the loss on the training sample) you can get?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gRzvovJvkQB1",
        "outputId": "d3b82658-d45c-4a84-a79f-eee8a6db2bce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(50, 11)\n",
            "(50,)\n",
            "(50,)\n"
          ]
        }
      ],
      "source": [
        "# Initialise weights with suitable random distributions\n",
        "hidden_nodes = 50 # number of nodes in the hidden layer\n",
        "n_inputs = 11 # input features in the dataset\n",
        "\n",
        "W = np.random.randn(hidden_nodes,11)*np.sqrt(2./n_inputs)\n",
        "b = np.random.randn(hidden_nodes)*np.sqrt(2./n_inputs)\n",
        "Wp = np.random.randn(hidden_nodes)*np.sqrt(2./hidden_nodes)\n",
        "bp = np.random.randn((1))\n",
        "\n",
        "print(W.shape)\n",
        "print(b.shape)\n",
        "print(Wp.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZI4TGelKkQB2"
      },
      "outputs": [],
      "source": [
        "# You can use this implementation of the ReLu activation function\n",
        "def relu(x):\n",
        "    return np.maximum(x, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qzR88W_okQB2"
      },
      "outputs": [],
      "source": [
        "def dnn(x,W,b,Wp,bp):\n",
        "    y = Wp*relu(np.dot(W,x)+b)+bp\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "rFp4e-RhkQB3"
      },
      "outputs": [],
      "source": [
        "def update_weights(x,y, W, b, Wp, bp):\n",
        "    \n",
        "    learning_rate = 0.01\n",
        "\n",
        "    out = dnn(x,W,b,Wp,bp)\n",
        "\n",
        "\n",
        "    bp_prime = 2*(out-y)\n",
        "\n",
        "    bk_prime = 2*(out-y)*Wp* np.heaviside(np.dot(W,x) + b,0)\n",
        "\n",
        "    Wpk_prime = 2*(out-y)*relu(np.dot(W,x) + b)\n",
        "    \n",
        "    Wk_prime = np.outer(2*(out-y)*Wp * np.heaviside(np.dot(W,x) + b,0), x) \n",
        "\n",
        "\n",
        "    W_new = W - learning_rate * Wk_prime\n",
        "    b_new = b - learning_rate * bk_prime\n",
        "    Wp_new = Wp - learning_rate * Wpk_prime\n",
        "    bp_new = bp - learning_rate * bp_prime\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # TODO: Derive the gradient for each of W,b,Wp,bp by taking the partial\n",
        "    # derivative of the loss function with respect to the variable and\n",
        "    # then implement the resulting weight-update procedure\n",
        "    # See Hint 2 for additional information\n",
        "\n",
        "    # You might need these numpy functions:\n",
        "    # np.dot, np.outer, np.heaviside\n",
        "    # Hint: Use .shape and print statements to make sure all operations\n",
        "    # do what you want them to \n",
        "    \n",
        "    # TODO: Update the weights/bias following the rule:  weight_new = weight_old - learning_rate * gradient\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    return W_new, b_new, Wp_new, bp_new # return the new weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guL8sB2ikQB3"
      },
      "source": [
        "# Training loop and evaluation below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uSr8cC6-kQB4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 Train Loss: 0.803387321937094 Test Loss: 0.7673906132492848\n",
            "Best loss: 0.7673906132492848 Final loss: 0.7673906132492848\n",
            "Correlation coefficient: -4.495123611472195e-17\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# The code below implements the training.\n",
        "# If you correctly implement  dnn and update_weights above, \n",
        "# you should not need to change anything below. \n",
        "# (apart from increasing the number of epochs)\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "# How many epochs to train\n",
        "# This will just train for one epoch\n",
        "# You will want a higher number once everything works\n",
        "n_epochs = 1 \n",
        "\n",
        "# Loop over the epochs\n",
        "for ep in range(n_epochs):\n",
        "        \n",
        "    # Each epoch is a complete over the training data\n",
        "    for i in range(X_train.shape[0]):\n",
        "        \n",
        "        # pick one example\n",
        "        x = X_train[i]\n",
        "        y = y_train[i]\n",
        "\n",
        "        # use it to update the weights\n",
        "        W,b,Wp,bp = update_weights(x,y,W,b,Wp,bp)\n",
        "    \n",
        "    # Calculate predictions for the full training and testing sample\n",
        "    y_pred_train = [dnn(x,W,b,Wp,bp)[0] for x in X_train]\n",
        "    y_pred = [dnn(x,W,b,Wp,bp)[0] for x in X_test]\n",
        "\n",
        "    # Calculate aver loss / example over the epoch\n",
        "    train_loss = sum((y_pred_train-y_train)**2) / y_train.shape[0]\n",
        "    test_loss = sum((y_pred-y_test)**2) / y_test.shape[0] \n",
        "    \n",
        "    # print some information\n",
        "    print(\"Epoch:\",ep, \"Train Loss:\", train_loss, \"Test Loss:\", test_loss)\n",
        "    \n",
        "    # and store the losses for later use\n",
        "    train_losses.append(train_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    \n",
        "    \n",
        "# After the training:\n",
        "    \n",
        "# Prepare scatter plot\n",
        "y_pred = [dnn(x,W,b,Wp,bp)[0] for x in X_test]\n",
        "\n",
        "print(\"Best loss:\", min(test_losses), \"Final loss:\", test_losses[-1])\n",
        "\n",
        "print(\"Correlation coefficient:\", np.corrcoef(y_pred,y_test)[0,1])\n",
        "plt.scatter(y_pred_train,y_train)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()\n",
        "\n",
        "# Prepare and loss over time\n",
        "plt.plot(train_losses,label=\"train\")\n",
        "plt.plot(test_losses,label=\"test\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Nen08epkQB4"
      },
      "source": [
        "# Hint 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "escPUs3CkQB5"
      },
      "source": [
        "We want a network with one hidden layer. As activiation in the hidden layer $\\sigma$ we apply element-wise ReLu, while no activation is used for the output layer. The forward pass of the network then reads:\n",
        "$$\\hat{y}=\\mathbf{W}^{\\prime} \\sigma(\\mathbf{W} \\vec{x}+\\vec{b})+b^{\\prime}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DRDzLi2kQB5"
      },
      "source": [
        "# Hint 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN01itNUkQB5"
      },
      "source": [
        "For the regression problem the objective function is the mean squared error between the prediction and the true label $y$: \n",
        "$$\n",
        "L=(\\hat{y}-y)^{2}\n",
        "$$\n",
        "\n",
        "Taking the partial derivatives - and diligently the applying chain rule - with respect to the different objects yields:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\frac{\\partial L}{\\partial b^{\\prime}} &=2(\\hat{y}-y) \\\\\n",
        "\\frac{\\partial L}{\\partial b_{k}} &=2(\\hat{y}-y) \\mathbf{W}_{k}^{\\prime} \\theta\\left(\\sum_{i} \\mathbf{W}_{i k} x_{i}+b_{k}\\right) \\\\\n",
        "\\frac{\\partial L}{\\partial \\mathbf{W}_{k}^{\\prime}} &=2(\\hat{y}-y) \\sigma\\left(\\sum_{i} \\mathbf{W}_{i k} x_{i}+b_{k}\\right) \\\\\n",
        "\\frac{\\partial L}{\\partial \\mathbf{W}_{k m}} &=2(\\hat{y}-y) \\mathbf{W}_{m}^{\\prime} \\theta\\left(\\sum_{i} \\mathbf{W}_{i m} x_{i}+b_{m}\\right) x_{k}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Here, $\\Theta$ denotes the Heaviside step function."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "8abb39f3f2e1189e894dd88a675edf8bb405facd55ab0e301d9edd135c41f248"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
